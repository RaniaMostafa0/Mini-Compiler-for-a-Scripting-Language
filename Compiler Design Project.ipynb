{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fh3dpvedLlX",
        "outputId": "93593954-568e-4ff2-89e5-aaf43b9e56f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the source code:\n",
            "BEGIN     LET a = 10     LET b = 20     LET c = a + b * 2     IF c >= 50 OR c == 100 THEN         CALL process(c)     ELSE         CALL retry()     ENDIF END\n",
            "\n",
            "=== PHASE 1 RESULTS (Scanner) ===\n",
            "Tokens:\n",
            "  Token: begin, Lexeme: BEGIN\n",
            "  Token: let, Lexeme: LET\n",
            "  Token: identifier, Lexeme: a\n",
            "  Token: equal, Lexeme: =\n",
            "  Token: number, Lexeme: 10\n",
            "  Token: let, Lexeme: LET\n",
            "  Token: identifier, Lexeme: b\n",
            "  Token: equal, Lexeme: =\n",
            "  Token: number, Lexeme: 20\n",
            "  Token: let, Lexeme: LET\n",
            "  Token: identifier, Lexeme: c\n",
            "  Token: equal, Lexeme: =\n",
            "  Token: identifier, Lexeme: a\n",
            "  Token: operator, Lexeme: +\n",
            "  Token: identifier, Lexeme: b\n",
            "  Token: operator, Lexeme: *\n",
            "  Token: number, Lexeme: 2\n",
            "  Token: if, Lexeme: IF\n",
            "  Token: identifier, Lexeme: c\n",
            "  Token: greater_equal, Lexeme: >=\n",
            "  Token: number, Lexeme: 50\n",
            "  Token: logical_operator, Lexeme: OR\n",
            "  Token: identifier, Lexeme: c\n",
            "  Token: equal_equal, Lexeme: ==\n",
            "  Token: number, Lexeme: 100\n",
            "  Token: then, Lexeme: THEN\n",
            "  Token: call, Lexeme: CALL\n",
            "  Token: identifier, Lexeme: process\n",
            "  Token: left_paren, Lexeme: (\n",
            "  Token: identifier, Lexeme: c\n",
            "  Token: right_paren, Lexeme: )\n",
            "  Token: else, Lexeme: ELSE\n",
            "  Token: call, Lexeme: CALL\n",
            "  Token: identifier, Lexeme: retry\n",
            "  Token: left_paren, Lexeme: (\n",
            "  Token: right_paren, Lexeme: )\n",
            "  Token: endif, Lexeme: ENDIF\n",
            "  Token: end, Lexeme: END\n",
            "\n",
            "Symbol Table:\n",
            "  Name: a, Type: int\n",
            "  Name: b, Type: int\n",
            "  Name: c, Type: int\n",
            "  Name: process, Type: function (with parameters: c)\n",
            "  Name: retry, Type: function (with parameters: )\n",
            "\n",
            "=== PHASE 2 RESULTS (Parser) ===\n",
            "\n",
            "Parse Tree:\n",
            "\n",
            "└─Program\n",
            "   ├─begin: BEGIN\n",
            "   ├─statements\n",
            "   │  ├─declare_statement\n",
            "   │  │  ├─let: LET\n",
            "   │  │  ├─id: a\n",
            "   │  │  ├─equal: =\n",
            "   │  │  └─number: 10\n",
            "   │  ├─declare_statement\n",
            "   │  │  ├─let: LET\n",
            "   │  │  ├─id: b\n",
            "   │  │  ├─equal: =\n",
            "   │  │  └─number: 20\n",
            "   │  ├─declare_statement\n",
            "   │  │  ├─let: LET\n",
            "   │  │  ├─id: c\n",
            "   │  │  ├─equal: =\n",
            "   │  │  └─expression\n",
            "   │  │     ├─id: a\n",
            "   │  │     ├─operation: +\n",
            "   │  │     ├─id: b\n",
            "   │  │     ├─operation: *\n",
            "   │  │     └─number: 2\n",
            "   │  └─if_statement\n",
            "   │     ├─if: IF\n",
            "   │     ├─condition\n",
            "   │     │  ├─id: c\n",
            "   │     │  ├─operation: >=\n",
            "   │     │  ├─number: 50\n",
            "   │     │  ├─logical_operator: OR\n",
            "   │     │  └─condition\n",
            "   │     │     ├─id: c\n",
            "   │     │     ├─operation: ==\n",
            "   │     │     └─number: 100\n",
            "   │     ├─then_statement\n",
            "   │     │  ├─then: THEN\n",
            "   │     │  └─statements\n",
            "   │     │     └─call_statement\n",
            "   │     │        ├─call: CALL\n",
            "   │     │        ├─id: process\n",
            "   │     │        ├─left_paren: (\n",
            "   │     │        ├─args\n",
            "   │     │        │  └─id: c\n",
            "   │     │        └─right_paren: )\n",
            "   │     ├─else_statement\n",
            "   │     │  ├─else: ELSE\n",
            "   │     │  └─statements\n",
            "   │     │     └─call_statement\n",
            "   │     │        ├─call: CALL\n",
            "   │     │        ├─id: retry\n",
            "   │     │        ├─left_paren: (\n",
            "   │     │        └─right_paren: )\n",
            "   │     └─endif: ENDIF\n",
            "   └─end: END\n"
          ]
        }
      ],
      "source": [
        "########################################\n",
        "# PHASE 1: Lexical Analysis (Scanner)\n",
        "########################################\n",
        "\n",
        "def lexical_analysis():\n",
        "    source_code = input(\"Enter the source code:\\n\")\n",
        "    length = len(source_code)\n",
        "    position = 0\n",
        "    line = 1\n",
        "\n",
        "    tokens = []\n",
        "    st = {}  # Symbol table\n",
        "    keywords = {\n",
        "        \"LET\", \"IF\", \"THEN\", \"ELSE\", \"ENDIF\", \"CALL\", \"WHILE\",\n",
        "        \"FOR\", \"FUNC\", \"RETURN\", \"BEGIN\", \"END\", \"ENDWHILE\", \"DO\"\n",
        "    }\n",
        "    logical_operators = {\"AND\", \"OR\", \"NOT\"}\n",
        "    operators = {'+', '-', '*', '/', '<', '>', '+=', '-=', '=', '/=', '++', '--', '!=', '==', '>='}\n",
        "    spaces = {' ', '\\t', '\\n'}\n",
        "    brackets = {\n",
        "        '(': 'left_paren',\n",
        "        ')': 'right_paren',\n",
        "        ',': 'comma',\n",
        "        '{': 'left_brace',\n",
        "        '}': 'right_brace',\n",
        "        '[': 'left_bracket',\n",
        "        ']': 'right_bracket'\n",
        "    }\n",
        "\n",
        "    open_parentheses_count = 0\n",
        "    open_brackets_count = 0\n",
        "    open_strings = False\n",
        "\n",
        "    while position < length:\n",
        "        current_char = source_code[position]\n",
        "\n",
        "        # 1) Skip whitespace\n",
        "        if current_char in spaces:\n",
        "            if current_char == '\\n':\n",
        "                line += 1\n",
        "            position += 1\n",
        "            continue\n",
        "\n",
        "        # 2) Handle comments delimited by { ... }\n",
        "        if current_char == '{':\n",
        "            position += 1\n",
        "            while position < length and source_code[position] != '}':\n",
        "                if source_code[position] == '\\n':\n",
        "                    line += 1\n",
        "                position += 1\n",
        "            if position == length:\n",
        "                print(f\"Syntax Error: Unclosed comment at line {line}, position {position}\")\n",
        "                break\n",
        "            position += 1  # Skip '}'\n",
        "            continue\n",
        "\n",
        "        # 3) Handle string literals \"...\"\n",
        "        if current_char == '\"':\n",
        "            if open_strings:\n",
        "                print(f\"Syntax Error: Unclosed string at line {line}, position {position}\")\n",
        "                break\n",
        "            open_strings = True\n",
        "            position += 1\n",
        "            start = position\n",
        "            while position < length and source_code[position] != '\"':\n",
        "                if source_code[position] == '\\n':\n",
        "                    print(f\"Syntax Error: Unterminated string at line {line}, position {position}\")\n",
        "                    break\n",
        "                position += 1\n",
        "            if position == length:\n",
        "                print(f\"Syntax Error: Unterminated string at line {line}, position {position}\")\n",
        "                break\n",
        "            lexeme = source_code[start:position]\n",
        "            tokens.append(('string', lexeme))\n",
        "            position += 1  # Skip closing '\"'\n",
        "            open_strings = False\n",
        "            continue\n",
        "\n",
        "        # 4) Handle identifiers / keywords / logical operators\n",
        "        if current_char.isalpha() or current_char == '_':\n",
        "            start = position\n",
        "            while (position < length and\n",
        "                   (source_code[position].isalnum() or source_code[position] == '_')):\n",
        "                position += 1\n",
        "            lexeme = source_code[start:position]\n",
        "            upper_lexeme = lexeme.upper()\n",
        "            if upper_lexeme in keywords:\n",
        "                token_type = upper_lexeme.lower()\n",
        "            elif upper_lexeme in logical_operators:\n",
        "                token_type = 'logical_operator'\n",
        "            else:\n",
        "                token_type = 'identifier'\n",
        "            tokens.append((token_type, lexeme))\n",
        "            continue\n",
        "\n",
        "        # 5) Handle numbers (integer or float)\n",
        "        if current_char.isdigit():\n",
        "            start = position\n",
        "            has_decimal = False\n",
        "            while position < length and (source_code[position].isdigit() or source_code[position] == '.'):\n",
        "                if source_code[position] == '.':\n",
        "                    if has_decimal:\n",
        "                        print(f\"Syntax Error: Multiple decimals in number at line {line}, position {position}\")\n",
        "                        break\n",
        "                    has_decimal = True\n",
        "                position += 1\n",
        "            lexeme = source_code[start:position]\n",
        "            tokens.append(('number', lexeme))\n",
        "            continue\n",
        "\n",
        "        # 6) Handle operators (+, -, *, /, <, >, !=, ==, >=, etc.)\n",
        "        if current_char in '+-*/<>=!':\n",
        "            start = position\n",
        "            lexeme = current_char\n",
        "            position += 1\n",
        "            # Check for two-character operators\n",
        "            if position < length and source_code[position] in '=<>':\n",
        "                lexeme += source_code[position]\n",
        "                position += 1\n",
        "            if lexeme in operators:\n",
        "                if lexeme == '=':\n",
        "                    tokens.append(('equal', lexeme))\n",
        "                elif lexeme == '!=':\n",
        "                    tokens.append(('not_equal', lexeme))\n",
        "                elif lexeme == '==':\n",
        "                    tokens.append(('equal_equal', lexeme))\n",
        "                elif lexeme == '>=':\n",
        "                    tokens.append(('greater_equal', lexeme))\n",
        "                else:\n",
        "                    tokens.append(('operator', lexeme))\n",
        "            else:\n",
        "                tokens.append(('operator', current_char))\n",
        "            continue\n",
        "\n",
        "        # 7) Handle brackets/parentheses\n",
        "        if current_char in brackets:\n",
        "            token_type = brackets[current_char]\n",
        "            tokens.append((token_type, current_char))\n",
        "            position += 1\n",
        "            if current_char == '(':\n",
        "                open_parentheses_count += 1\n",
        "            elif current_char == ')':\n",
        "                open_parentheses_count -= 1\n",
        "            elif current_char == '[':\n",
        "                open_brackets_count += 1\n",
        "            elif current_char == ']':\n",
        "                open_brackets_count -= 1\n",
        "            continue\n",
        "\n",
        "        # Unknown character\n",
        "        print(f\"Syntax Error: Unknown character '{current_char}' at line {line}, position {position}\")\n",
        "        break\n",
        "\n",
        "    if open_parentheses_count > 0:\n",
        "        print(f\"Syntax Error: Unclosed parenthesis at the end of input.\")\n",
        "    if open_brackets_count > 0:\n",
        "        print(f\"Syntax Error: Unclosed bracket at the end of input.\")\n",
        "\n",
        "    # Symbol Table Population\n",
        "    i = 0\n",
        "    while i < len(tokens):\n",
        "        token_type, lexeme = tokens[i]\n",
        "\n",
        "        if token_type == \"let\":\n",
        "            i += 1\n",
        "            if i < len(tokens) and tokens[i][0] == \"identifier\":\n",
        "                var_name = tokens[i][1]\n",
        "                i += 1\n",
        "                if i < len(tokens) and tokens[i][0] == \"equal\":\n",
        "                    i += 1\n",
        "                    if i < len(tokens):\n",
        "                        value_token = tokens[i]\n",
        "                        value_type, value_lexeme = value_token\n",
        "\n",
        "                        if value_type == 'number':\n",
        "                            if '.' in value_lexeme:\n",
        "                                st[var_name] = 'float'\n",
        "                            else:\n",
        "                                st[var_name] = 'int'\n",
        "                        elif value_type == 'string':\n",
        "                            st[var_name] = 'string'\n",
        "                        elif value_type == 'logical_operator':\n",
        "                            st[var_name] = 'bool'\n",
        "                        elif value_type == 'left_bracket':\n",
        "                            # Handle list assignments (e.g., LET list = [1, 2, 3])\n",
        "                            list_elements = []\n",
        "                            i += 1\n",
        "                            while i < len(tokens) and tokens[i][0] != 'right_bracket':\n",
        "                                element_type, element_lexeme = tokens[i]\n",
        "                                if element_type == 'number':\n",
        "                                    list_elements.append(float(element_lexeme) if '.' in element_lexeme else int(element_lexeme))\n",
        "                                elif tokens[i][0] == \"comma\":\n",
        "                                    pass\n",
        "                                else:\n",
        "                                    print(f\"Syntax Error: Unexpected element in list at token {i}\")\n",
        "                                    break\n",
        "                                i += 1\n",
        "\n",
        "                            if i < len(tokens) and tokens[i][0] == \"right_bracket\":\n",
        "                                if all(isinstance(el, int) for el in list_elements):\n",
        "                                    st[var_name] = 'list of int'\n",
        "                                elif all(isinstance(el, float) for el in list_elements):\n",
        "                                    st[var_name] = 'list of float'\n",
        "                                else:\n",
        "                                    st[var_name] = 'list of mixed types'\n",
        "                            else:\n",
        "                                print(f\"Syntax Error: Expected ']' to close list at token {i}\")\n",
        "                        elif value_type == 'identifier':\n",
        "                            # Handle assignments from other variables or function calls\n",
        "                            if i + 1 < len(tokens) and tokens[i + 1][0] == 'left_paren':\n",
        "                                # Function call assignment (e.g., LET result = func(args))\n",
        "                                func_name = value_lexeme\n",
        "                                st[var_name] = 'unknown'  # Function return type can be determined in semantic analysis\n",
        "                            else:\n",
        "                                st[var_name] = st.get(value_lexeme, 'unknown')\n",
        "                        elif value_type in operators:\n",
        "                            print(f\"Syntax Error: Incomplete expression at token {i}, position {position}\")\n",
        "                        else:\n",
        "                            print(f\"Syntax Error: Unexpected value '{value_lexeme}' at token {i}\")\n",
        "                    else:\n",
        "                        print(f\"Syntax Error: Expected value after '=' at token {i}\")\n",
        "                else:\n",
        "                    print(f\"Syntax Error: Expected '=' after identifier at token {i}\")\n",
        "            else:\n",
        "                print(f\"Syntax Error: Expected identifier after 'LET' at token {i}\")\n",
        "\n",
        "        elif token_type in (\"call\", \"func\"):\n",
        "            i += 1\n",
        "            if i < len(tokens) and tokens[i][0] == \"identifier\":\n",
        "                func_name = tokens[i][1]\n",
        "                params = []\n",
        "                i += 1\n",
        "                if i < len(tokens) and tokens[i][0] == \"left_paren\":\n",
        "                    i += 1\n",
        "                    while i < len(tokens) and tokens[i][0] != \"right_paren\":\n",
        "                        if tokens[i][0] == \"identifier\":\n",
        "                            param_name = tokens[i][1]\n",
        "                            params.append(param_name)\n",
        "                            if param_name not in st:\n",
        "                                st[param_name] = 'unknown'\n",
        "                        elif tokens[i][0] == \"number\":\n",
        "                            params.append(tokens[i][1])\n",
        "                        elif tokens[i][0] == \"string\":\n",
        "                            params.append(f'\"{tokens[i][1]}\"')\n",
        "                        elif tokens[i][0] == \"comma\":\n",
        "                            pass\n",
        "                        else:\n",
        "                            print(f\"Syntax Error: Expected identifier or number in function parameters at token {i}, position {position}\")\n",
        "                            break\n",
        "                        i += 1\n",
        "                    if i < len(tokens) and tokens[i][0] == \"right_paren\":\n",
        "                        st[func_name] = f\"function (with parameters: {', '.join(params)})\"\n",
        "                    else:\n",
        "                        print(f\"Syntax Error: Expected ')' after function parameters at token {i}, position {position}\")\n",
        "                else:\n",
        "                    st[func_name] = \"function (with parameters: )\"\n",
        "                    i -= 1\n",
        "            else:\n",
        "                print(f\"Syntax Error: Expected function name after 'CALL' at token {i}, position {position}\")\n",
        "                i -= 1\n",
        "        else:\n",
        "            pass\n",
        "        i += 1\n",
        "\n",
        "    # Mark any identifiers not in symbol table as 'unknown'\n",
        "    for token_type, lexeme in tokens:\n",
        "        if token_type == 'identifier' and lexeme not in st:\n",
        "            st[lexeme] = 'unknown'\n",
        "\n",
        "    return tokens, st\n",
        "\n",
        "\n",
        "########################################\n",
        "# PHASE 2: Syntax Analysis (Parser)\n",
        "########################################\n",
        "\n",
        "class ParserError(Exception):\n",
        "    pass\n",
        "\n",
        "class ParseNode:\n",
        "    \"\"\"\n",
        "    A tree node that can print itself in a vertical ASCII style.\n",
        "    \"\"\"\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.children = []\n",
        "\n",
        "    def add_child(self, child):\n",
        "        if child is not None:\n",
        "            self.children.append(child)\n",
        "\n",
        "    def _print_tree(self, prefix=\"\", is_last=True):\n",
        "        \"\"\"\n",
        "        Recursively prints the tree in an ASCII structure:\n",
        "\n",
        "        Program\n",
        "        ├─ statements\n",
        "        │  └─ declare_statement\n",
        "        ...\n",
        "        \"\"\"\n",
        "        branch = \"└─\" if is_last else \"├─\"\n",
        "        print(prefix + branch + self.name)\n",
        "        next_prefix = prefix + (\"   \" if is_last else \"│  \")\n",
        "        for i, child in enumerate(self.children):\n",
        "            child_is_last = (i == len(self.children) - 1)\n",
        "            child._print_tree(next_prefix, child_is_last)\n",
        "\n",
        "    def print_tree(self):\n",
        "        self._print_tree()\n",
        "\n",
        "\n",
        "class RecursiveDescentParser:\n",
        "    def __init__(self, tokens):\n",
        "        self.tokens = tokens\n",
        "        self.pos = 0\n",
        "        self.current_token = self.tokens[self.pos] if self.tokens else None\n",
        "\n",
        "    def advance(self):\n",
        "        self.pos += 1\n",
        "        if self.pos < len(self.tokens):\n",
        "            self.current_token = self.tokens[self.pos]\n",
        "        else:\n",
        "            self.current_token = None\n",
        "\n",
        "    def match(self, expected_type=None):\n",
        "        \"\"\"Consume the current token if it matches expected_type, otherwise error.\"\"\"\n",
        "        if self.current_token is None:\n",
        "            raise ParserError(\"Unexpected end of tokens while matching.\")\n",
        "\n",
        "        ttype, tlex = self.current_token\n",
        "        if expected_type and ttype != expected_type:\n",
        "            raise ParserError(\n",
        "                f\"Syntax Error: expected {expected_type}, got {ttype} (lexeme='{tlex}') at pos {self.pos}\"\n",
        "            )\n",
        "\n",
        "        # Label tokens like \"let: LET\", \"id: a\", \"operator: +\", etc.\n",
        "        label_map = {\n",
        "            'let':          f\"let: {tlex}\",\n",
        "            'identifier':   f\"id: {tlex}\",\n",
        "            'equal':        f\"equal: {tlex}\",\n",
        "            'operator':     f\"operation: {tlex}\",\n",
        "            'not_equal':    f\"operation: {tlex}\",\n",
        "            'equal_equal':  f\"operation: {tlex}\",\n",
        "            'greater_equal': f\"operation: {tlex}\",\n",
        "            'number':       f\"number: {tlex}\",\n",
        "            'string':       f\"string: {tlex}\",\n",
        "            'if':           f\"if: {tlex}\",\n",
        "            'then':         f\"then: {tlex}\",\n",
        "            'else':         f\"else: {tlex}\",\n",
        "            'endif':        f\"endif: {tlex}\",\n",
        "            'call':         f\"call: {tlex}\",\n",
        "            'begin':        f\"begin: {tlex}\",\n",
        "            'end':          f\"end: {tlex}\",\n",
        "            'left_paren':   f\"left_paren: {tlex}\",\n",
        "            'right_paren':  f\"right_paren: {tlex}\",\n",
        "            'comma':        f\"comma: {tlex}\",\n",
        "            'logical_operator': f\"logical_operator: {tlex}\"\n",
        "        }\n",
        "        label = label_map.get(ttype, f\"{ttype}: {tlex}\")\n",
        "\n",
        "        node = ParseNode(label)\n",
        "        self.advance()\n",
        "        return node\n",
        "\n",
        "    def parse(self):\n",
        "        root = self.parse_program()\n",
        "        if self.current_token is not None:\n",
        "            ttype, tlex = self.current_token\n",
        "            raise ParserError(f\"Extra tokens remain: {ttype}('{tlex}') at pos {self.pos}\")\n",
        "        return root\n",
        "\n",
        "    ###################################\n",
        "    # Grammar Rules\n",
        "    ###################################\n",
        "\n",
        "    # Program -> begin statements end\n",
        "    def parse_program(self):\n",
        "        program_node = ParseNode(\"Program\")\n",
        "\n",
        "        # must see 'begin'\n",
        "        if not self.current_token or self.current_token[0] != 'begin':\n",
        "            raise ParserError(\"Program must start with 'BEGIN'\")\n",
        "        begin_node = self.match('begin')\n",
        "        program_node.add_child(begin_node)\n",
        "\n",
        "        # statements\n",
        "        sb = self.parse_statements()\n",
        "        program_node.add_child(sb)\n",
        "\n",
        "        # must see 'end'\n",
        "        if not self.current_token or self.current_token[0] != 'end':\n",
        "            raise ParserError(\"Program must end with 'END'\")\n",
        "        end_node = self.match('end')\n",
        "        program_node.add_child(end_node)\n",
        "\n",
        "        return program_node\n",
        "\n",
        "    # statements -> statement statements | (empty)\n",
        "    def parse_statements(self):\n",
        "        sb_node = ParseNode(\"statements\")\n",
        "\n",
        "        while self.current_token is not None:\n",
        "            ttype, _ = self.current_token\n",
        "            if ttype in ('end', 'endif', 'else', 'endwhile'):\n",
        "                break\n",
        "            stmt = self.parse_statement()\n",
        "            sb_node.add_child(stmt)\n",
        "\n",
        "        return sb_node\n",
        "\n",
        "    # statement -> declare_statement | call_statement | if_statement | ...\n",
        "    def parse_statement(self):\n",
        "        if not self.current_token:\n",
        "            return None\n",
        "\n",
        "        ttype, tlex = self.current_token\n",
        "        if ttype == 'let':\n",
        "            return self.parse_declare_statement()\n",
        "        elif ttype == 'call':\n",
        "            return self.parse_call_statement()\n",
        "        elif ttype == 'if':\n",
        "            return self.parse_if_statement()\n",
        "        else:\n",
        "            raise ParserError(f\"Syntax Error: unexpected token {ttype}('{tlex}') in statement\")\n",
        "\n",
        "    # declare_statement -> let identifier equal expression\n",
        "    def parse_declare_statement(self):\n",
        "        node = ParseNode(\"declare_statement\")\n",
        "\n",
        "        let_node = self.match('let')\n",
        "        node.add_child(let_node)\n",
        "\n",
        "        if not self.current_token or self.current_token[0] != 'identifier':\n",
        "            raise ParserError(\"Expected identifier after 'let'\")\n",
        "        id_node = self.match('identifier')\n",
        "        node.add_child(id_node)\n",
        "\n",
        "        if not self.current_token or self.current_token[0] != 'equal':\n",
        "            raise ParserError(\"Expected '=' in declaration\")\n",
        "        eq_node = self.match('equal')\n",
        "        node.add_child(eq_node)\n",
        "\n",
        "        # parse_expression might return a single child (like \"number: 5\")\n",
        "        # or an \"expression\" node (if there's an operator).\n",
        "        expr_node = self.parse_expression()\n",
        "        node.add_child(expr_node)\n",
        "\n",
        "        return node\n",
        "\n",
        "    # call_statement -> call identifier ( args )\n",
        "    def parse_call_statement(self):\n",
        "        node = ParseNode(\"call_statement\")\n",
        "\n",
        "        call_node = self.match('call')\n",
        "        node.add_child(call_node)\n",
        "\n",
        "        if not self.current_token or self.current_token[0] != 'identifier':\n",
        "            raise ParserError(\"Expected identifier after 'call'\")\n",
        "        func_id = self.match('identifier')\n",
        "        node.add_child(func_id)\n",
        "\n",
        "        if not self.current_token or self.current_token[0] != 'left_paren':\n",
        "            raise ParserError(\"Expected '(' after function name\")\n",
        "        lp = self.match('left_paren')\n",
        "        node.add_child(lp)\n",
        "\n",
        "        if self.current_token and self.current_token[0] != 'right_paren':\n",
        "            args_node = self.parse_args()\n",
        "            node.add_child(args_node)\n",
        "\n",
        "        if not self.current_token or self.current_token[0] != 'right_paren':\n",
        "            raise ParserError(\"Expected ')' at the end of call statement\")\n",
        "        rp = self.match('right_paren')\n",
        "        node.add_child(rp)\n",
        "\n",
        "        return node\n",
        "\n",
        "    # args -> expression ( comma expression )*\n",
        "    def parse_args(self):\n",
        "        args_node = ParseNode(\"args\")\n",
        "\n",
        "        first_expr = self.parse_expression()\n",
        "        args_node.add_child(first_expr)\n",
        "\n",
        "        while self.current_token and self.current_token[0] == 'comma':\n",
        "            cnode = self.match('comma')\n",
        "            args_node.add_child(cnode)\n",
        "            e = self.parse_expression()\n",
        "            args_node.add_child(e)\n",
        "\n",
        "        return args_node\n",
        "\n",
        "    # if_statement -> if condition then then_statements else_part? endif\n",
        "    def parse_if_statement(self):\n",
        "        if_node = ParseNode(\"if_statement\")\n",
        "\n",
        "        if_tok = self.match('if')\n",
        "        if_node.add_child(if_tok)\n",
        "\n",
        "        cond = self.parse_condition()\n",
        "        if_node.add_child(cond)\n",
        "\n",
        "        if not self.current_token or self.current_token[0] != 'then':\n",
        "            raise ParserError(\"Expected 'THEN' after if condition\")\n",
        "        then_tok = self.match('then')\n",
        "        then_stmt = ParseNode(\"then_statement\")\n",
        "        then_stmt.add_child(then_tok)\n",
        "\n",
        "        # parse statements inside 'then'\n",
        "        then_stmts = self.parse_statements()\n",
        "        then_stmt.add_child(then_stmts)\n",
        "        if_node.add_child(then_stmt)\n",
        "\n",
        "        # optional else\n",
        "        if self.current_token and self.current_token[0] == 'else':\n",
        "            else_tok = self.match('else')\n",
        "            else_stmt = ParseNode(\"else_statement\")\n",
        "            else_stmt.add_child(else_tok)\n",
        "            else_stmts = self.parse_statements()\n",
        "            else_stmt.add_child(else_stmts)\n",
        "            if_node.add_child(else_stmt)\n",
        "\n",
        "        if not self.current_token or self.current_token[0] != 'endif':\n",
        "            raise ParserError(\"Missing 'ENDIF' at end of if statement\")\n",
        "        endif_tok = self.match('endif')\n",
        "        if_node.add_child(endif_tok)\n",
        "\n",
        "        return if_node\n",
        "\n",
        "    # condition -> expression (comparison_operator expression)? (logical_operator condition)*\n",
        "    def parse_condition(self):\n",
        "        cond_node = ParseNode(\"condition\")\n",
        "\n",
        "        left_expr = self.parse_expression()\n",
        "        cond_node.add_child(left_expr)\n",
        "\n",
        "        # Comparison Operators: <, >, <=, >=, ==, !=\n",
        "        if self.current_token and self.current_token[0] in ('operator', 'not_equal', 'equal_equal', 'greater_equal'):\n",
        "            op_node = self.match(self.current_token[0])\n",
        "            cond_node.add_child(op_node)\n",
        "            right_expr = self.parse_expression()\n",
        "            cond_node.add_child(right_expr)\n",
        "\n",
        "        # Logical Operators: AND, OR, NOT\n",
        "        while self.current_token and self.current_token[0] == 'logical_operator':\n",
        "            log_op_node = self.match('logical_operator')\n",
        "            cond_node.add_child(log_op_node)\n",
        "            next_cond = self.parse_condition()\n",
        "            cond_node.add_child(next_cond)\n",
        "\n",
        "        return cond_node\n",
        "\n",
        "    # *****************************************************\n",
        "    # expression -> factor ( operator factor )*\n",
        "    # If there are NO operators, we return just the factor\n",
        "    # If there's at least one operator, we create an \"expression\" node\n",
        "    # *****************************************************\n",
        "    def parse_expression(self):\n",
        "        left_factor = self.parse_factor()\n",
        "\n",
        "        # Collect subsequent (operator factor) pairs\n",
        "        extra_ops = []\n",
        "        while self.current_token and self.current_token[0] == 'operator':\n",
        "            op_lex = self.current_token[1]\n",
        "            # Only parse if it's +, -, *, or /\n",
        "            if op_lex not in ('+', '-', '*', '/'):\n",
        "                break\n",
        "            op_node = self.match('operator')\n",
        "            fac_node = self.parse_factor()\n",
        "            extra_ops.append(op_node)\n",
        "            extra_ops.append(fac_node)\n",
        "\n",
        "        # If NO operators, return the factor node alone (no \"expression\" wrap)\n",
        "        if not extra_ops:\n",
        "            return left_factor\n",
        "\n",
        "        # Otherwise build an \"expression\" node\n",
        "        expr_node = ParseNode(\"expression\")\n",
        "        expr_node.add_child(left_factor)\n",
        "        for item in extra_ops:\n",
        "            expr_node.add_child(item)\n",
        "        return expr_node\n",
        "\n",
        "    # factor -> number | identifier | string | ( expression )\n",
        "    def parse_factor(self):\n",
        "        if not self.current_token:\n",
        "            raise ParserError(\"Unexpected end in factor.\")\n",
        "\n",
        "        ttype, tlex = self.current_token\n",
        "        if ttype == 'number':\n",
        "            return self.match('number')\n",
        "        elif ttype == 'identifier':\n",
        "            return self.match('identifier')\n",
        "        elif ttype == 'string':\n",
        "            return self.match('string')\n",
        "        elif ttype == 'left_paren':\n",
        "            lp = self.match('left_paren')\n",
        "            expr = self.parse_expression()\n",
        "            if not self.current_token or self.current_token[0] != 'right_paren':\n",
        "                raise ParserError(\"Missing ')' in factor.\")\n",
        "            rp = self.match('right_paren')\n",
        "\n",
        "            # Wrap in a node to keep track of parentheses\n",
        "            group_node = ParseNode(\"expression_group\")\n",
        "            group_node.add_child(lp)\n",
        "            group_node.add_child(expr)\n",
        "            group_node.add_child(rp)\n",
        "            return group_node\n",
        "        else:\n",
        "            raise ParserError(f\"Unexpected token '{tlex}' in factor.\")\n",
        "\n",
        "\n",
        "########################################\n",
        "# Main Driver\n",
        "########################################\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    tokens, st = lexical_analysis()\n",
        "\n",
        "    print(\"\\n=== PHASE 1 RESULTS (Scanner) ===\")\n",
        "    print(\"Tokens:\")\n",
        "    for token in tokens:\n",
        "        token_type, lexeme = token\n",
        "        print(f\"  Token: {token_type}, Lexeme: {lexeme}\")\n",
        "\n",
        "    print(\"\\nSymbol Table:\")\n",
        "    for name, type_ in st.items():\n",
        "        print(f\"  Name: {name}, Type: {type_}\")\n",
        "\n",
        "    print(\"\\n=== PHASE 2 RESULTS (Parser) ===\")\n",
        "    if not tokens:\n",
        "        print(\"No tokens to parse.\")\n",
        "    else:\n",
        "        parser = RecursiveDescentParser(tokens)\n",
        "        try:\n",
        "            parse_tree = parser.parse()\n",
        "            print(\"\\nParse Tree:\\n\")\n",
        "            parse_tree.print_tree()\n",
        "        except ParserError as e:\n",
        "            print(\"Parser Error:\", e)\n"
      ]
    }
  ]
}